{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ramyajoshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense\n",
    "from tensorflow.keras.layers import Flatten, LSTM\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import sklearn.utils\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "df1_type=pd.read_csv(\"event_type.csv\",encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Certifications</td>\n",
       "      <td>{Certifications}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Certifications</td>\n",
       "      <td>{Certifications}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Certifications</td>\n",
       "      <td>{Certifications}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Certifications</td>\n",
       "      <td>{Certifications}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Certifications</td>\n",
       "      <td>{Certifications}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1078</td>\n",
       "      <td>Webinars</td>\n",
       "      <td>{Webinars}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1079</td>\n",
       "      <td>Courses</td>\n",
       "      <td>{Courses}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>Expos</td>\n",
       "      <td>{Expos}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1081</td>\n",
       "      <td>Webinars</td>\n",
       "      <td>{Webinars}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1082</td>\n",
       "      <td>Workshops</td>\n",
       "      <td>{Workshops}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1083 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Type             total\n",
       "0     Certifications  {Certifications}\n",
       "1     Certifications  {Certifications}\n",
       "2     Certifications  {Certifications}\n",
       "3     Certifications  {Certifications}\n",
       "4     Certifications  {Certifications}\n",
       "...              ...               ...\n",
       "1078        Webinars        {Webinars}\n",
       "1079         Courses         {Courses}\n",
       "1080           Expos           {Expos}\n",
       "1081        Webinars        {Webinars}\n",
       "1082       Workshops       {Workshops}\n",
       "\n",
       "[1083 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_type=df1_type.iloc[ : ,[1]]\n",
    "df2_type=df2_type.replace(np.nan,'')\n",
    "l1=list()\n",
    "l1=df2_type.values.tolist()\n",
    "df2_type['total']=pd.Series(l1).values\n",
    "df2_type['total']=df2_type['total'].apply(set)\n",
    "\n",
    "df2_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Management</td>\n",
       "      <td>{Management}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Management</td>\n",
       "      <td>{Management}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Management</td>\n",
       "      <td>{Management}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Management</td>\n",
       "      <td>{Management}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Management</td>\n",
       "      <td>{Management}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1077</td>\n",
       "      <td>Other</td>\n",
       "      <td>{Other}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1078</td>\n",
       "      <td>Other</td>\n",
       "      <td>{Other}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1079</td>\n",
       "      <td>Other</td>\n",
       "      <td>{Other}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>Other</td>\n",
       "      <td>{Other}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1081</td>\n",
       "      <td>Other</td>\n",
       "      <td>{Other}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1082 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Domain         total\n",
       "0     Management  {Management}\n",
       "1     Management  {Management}\n",
       "2     Management  {Management}\n",
       "3     Management  {Management}\n",
       "4     Management  {Management}\n",
       "...          ...           ...\n",
       "1077       Other       {Other}\n",
       "1078       Other       {Other}\n",
       "1079       Other       {Other}\n",
       "1080       Other       {Other}\n",
       "1081       Other       {Other}\n",
       "\n",
       "[1082 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_domain=pd.read_csv(\"event_domainfinal.csv\",encoding='latin1')\n",
    "df2_domain=df1_domain.iloc[ : ,[1]]\n",
    "df2_doamin=df2_domain.replace(np.nan,'')\n",
    "l2=list()\n",
    "l2=df2_domain.values.tolist()\n",
    "df2_domain['total']=pd.Series(l2).values\n",
    "#print(df2)\n",
    "df2_domain['total']=df2_domain['total'].apply(set)\n",
    "df2_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Certifications' 'Competitions' 'Courses' 'Expos' 'Fests' 'Hackathon'\n",
      " 'Internships' 'Jobs' 'Talks' 'Training' 'Webinars' 'Workshops']\n",
      "                                               Event  Certifications  \\\n",
      "0                  Spring cloud training- Free demo                0   \n",
      "1  Mindmajix Provides .NET Training Online with a...               0   \n",
      "2                              Beginner Code Champ 7               0   \n",
      "3                  Smart city festival is awaiting!!               0   \n",
      "4   Workshop - Kerala State Higher Education Council               0   \n",
      "\n",
      "   Competitions  Courses  Expos  Fests  Hackathon  Internships  Jobs  Talks  \\\n",
      "0             0        0      0      0          0            0     0      0   \n",
      "1             0        0      0      0          0            0     0      0   \n",
      "2             0        0      0      0          1            0     0      0   \n",
      "3             0        0      0      1          0            0     0      0   \n",
      "4             0        0      0      0          0            0     0      0   \n",
      "\n",
      "   Training  Webinars  Workshops  \n",
      "0         1         0          0  \n",
      "1         1         0          0  \n",
      "2         0         0          0  \n",
      "3         0         0          0  \n",
      "4         0         0          1  \n",
      "['Artificial Intelligence' 'Blockchain' 'C' 'C++' 'Cloud Computing'\n",
      " 'Coding' 'Data Science' 'Development Process' 'Finance' 'Hardware'\n",
      " 'Higher Education' 'IoT' 'Java' 'Javascript' 'Machine Learning'\n",
      " 'Management' 'Mobile Applications' 'Networking' 'Other' 'Python'\n",
      " 'Security' 'Software Architecture' 'Web Development']\n",
      "                                               Event  Artificial Intelligence  \\\n",
      "0                          Microsoft Azure Training                         0   \n",
      "1  10 hours bootcamp on Introduction to Computer ...                        0   \n",
      "2       What are some cool C++ programming projects?                        0   \n",
      "3              Secure Software Design Specialization                        0   \n",
      "4        Big Data Analysis and Data Mining. Virtual.                        0   \n",
      "\n",
      "   Blockchain  C  C++  Cloud Computing  Coding  Data Science  \\\n",
      "0           0  0    0                1       0             0   \n",
      "1           0  0    0                0       0             0   \n",
      "2           0  0    1                0       0             0   \n",
      "3           0  0    0                0       0             0   \n",
      "4           0  0    0                0       0             1   \n",
      "\n",
      "   Development Process  Finance  ...  Javascript  Machine Learning  \\\n",
      "0                    0        0  ...           0                 0   \n",
      "1                    0        0  ...           0                 0   \n",
      "2                    0        0  ...           0                 0   \n",
      "3                    0        0  ...           0                 0   \n",
      "4                    0        0  ...           0                 0   \n",
      "\n",
      "   Management  Mobile Applications  Networking  Other  Python  Security  \\\n",
      "0           0                    0           0      0       0         0   \n",
      "1           0                    0           0      0       0         0   \n",
      "2           0                    0           0      0       0         0   \n",
      "3           0                    0           0      0       0         0   \n",
      "4           0                    0           0      0       0         0   \n",
      "\n",
      "   Software Architecture  Web Development  \n",
      "0                      0                0  \n",
      "1                      0                0  \n",
      "2                      0                0  \n",
      "3                      1                0  \n",
      "4                      0                0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "l_type=mlb.fit_transform(df2_type['total'])\n",
    "df3_type=pd.DataFrame(l_type)\n",
    "df3_type.columns=list(mlb.classes_)\n",
    "#df3=df3.drop(columns=[''])\n",
    "print(mlb.classes_)\n",
    "data=pd.Series(df1_type['Event'])\n",
    "df3_type.insert(0,'Event',data)\n",
    "df3_type = sklearn.utils.shuffle(df3_type)\n",
    "df3_type = df3_type.reset_index(drop=True)\n",
    "print(df3_type.head())\n",
    "\n",
    "\n",
    "l_domain=mlb.fit_transform(df2_domain['total'])\n",
    "df3_domain=pd.DataFrame(l_domain)\n",
    "df3_domain.columns=list(mlb.classes_)\n",
    "#df3=df3.drop(columns=[''])\n",
    "print(mlb.classes_)\n",
    "data=pd.Series(df1_domain['Event'])\n",
    "df3_domain.insert(0,'Event',data)\n",
    "df3_domain = sklearn.utils.shuffle(df3_domain)\n",
    "df3_domain = df3_domain.reset_index(drop=True)\n",
    "print(df3_domain.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence =str(re.sub('[^0-9a-zA-Z]', ' ',str(sen)))\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "   \n",
    "    sentence=str.lower(sentence)\n",
    "    \n",
    "    text_tokens = word_tokenize(sentence)\n",
    "\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "    filtered_sentence = (\" \").join(tokens_without_sw)\n",
    "\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_type = []\n",
    "x_domain=[]\n",
    "sentences1 = list(df3_type[\"Event\"])\n",
    "sentences2 = list(df3_domain[\"Event\"])\n",
    "for sen in sentences1:\n",
    "    x_type.append(preprocess_text(sen))\n",
    "for sen in sentences2:\n",
    "    x_domain.append(preprocess_text(sen))\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1083, 200)\n",
      "(1082, 200)\n"
     ]
    }
   ],
   "source": [
    "tokenizer1 = Tokenizer()\n",
    "tokenizer1.fit_on_texts(x_type)\n",
    "X_data_type = tokenizer1.texts_to_sequences(x_type)\n",
    "vocab_size1 = len(tokenizer1.word_index) + 1\n",
    "\n",
    "tokenizer2 = Tokenizer()\n",
    "tokenizer2.fit_on_texts(x_domain)\n",
    "X_data_domain = tokenizer2.texts_to_sequences(x_domain)\n",
    "vocab_size2 = len(tokenizer2.word_index) + 1\n",
    "\n",
    "maxlen = 200\n",
    "X_data_type = pad_sequences(X_data_type, padding='post', maxlen=maxlen)\n",
    "X_data_domain = pad_sequences(X_data_domain, padding='post', maxlen=maxlen)\n",
    "print(X_data_type.shape)\n",
    "print(X_data_domain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1083, 12)\n",
      "(1082, 23)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "event_type=df3_type[['Certifications','Competitions','Courses','Expos','Fests','Hackathon','Internships','Jobs','Talks','Training','Webinars','Workshops']]\n",
    "event_domain=df3_domain[['Artificial Intelligence' ,'Blockchain', 'C' ,'C++' ,'Cloud Computing',\n",
    " 'Coding', 'Data Science', 'Development Process', 'Finance' ,'Hardware',\n",
    " 'Higher Education' ,'IoT', 'Java' ,'Javascript', 'Machine Learning',\n",
    " 'Management' ,'Mobile Applications', 'Networking' ,'Other','Python',\n",
    " 'Security' ,'Software Architecture', 'Web Development']]\n",
    "y_type = event_type.values\n",
    "y_domain = event_domain.values\n",
    "print(y_type.shape)\n",
    "print(y_domain.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dictionary = dict()\n",
    "\n",
    "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix1 = zeros((vocab_size1, 100))\n",
    "for word, index in tokenizer1.word_index.items():\n",
    "    embedding_vector1 = embeddings_dictionary.get(word)\n",
    "    if embedding_vector1 is not None:\n",
    "        embedding_matrix1[index] = embedding_vector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix2 = zeros((vocab_size2, 100))\n",
    "for word, index in tokenizer2.word_index.items():\n",
    "    embedding_vector2 = embeddings_dictionary.get(word)\n",
    "    if embedding_vector2 is not None:\n",
    "        embedding_matrix2[index] = embedding_vector2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = tf.keras.layers.Input(shape=(maxlen,))\n",
    " \n",
    "x1 = tf.keras.layers.Embedding(vocab_size1,100, weights=[embedding_matrix1], trainable=False)(input1)\n",
    "\n",
    "x1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True, dropout=0.1,\n",
    "                                                      recurrent_dropout=0.1))(x1)\n",
    " \n",
    "x1= tf.keras.layers.Conv1D(64, kernel_size=3, padding=\"valid\", kernel_initializer=\"glorot_uniform\")(x1)\n",
    " \n",
    "avg_pool1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "max_pool1 = tf.keras.layers.GlobalMaxPooling1D()(x1)\n",
    " \n",
    "x1 = tf.keras.layers.concatenate([avg_pool1, max_pool1])\n",
    " \n",
    "preds1 = tf.keras.layers.Dense(12, activation=\"sigmoid\")(x1)\n",
    " \n",
    "model1 = tf.keras.Model(input1, preds1)\n",
    " \n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 866 samples, validate on 217 samples\n",
      "Epoch 1/5\n",
      "866/866 [==============================] - 51s 59ms/sample - loss: 0.0755 - accuracy: 0.9763 - val_loss: 0.0833 - val_accuracy: 0.9731\n",
      "Epoch 2/5\n",
      "866/866 [==============================] - 47s 54ms/sample - loss: 0.0591 - accuracy: 0.9809 - val_loss: 0.0768 - val_accuracy: 0.9758\n",
      "Epoch 3/5\n",
      "866/866 [==============================] - 48s 55ms/sample - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.0725 - val_accuracy: 0.9750\n",
      "Epoch 4/5\n",
      "866/866 [==============================] - 49s 57ms/sample - loss: 0.0391 - accuracy: 0.9882 - val_loss: 0.0692 - val_accuracy: 0.9785\n",
      "Epoch 5/5\n",
      "866/866 [==============================] - 50s 58ms/sample - loss: 0.0316 - accuracy: 0.9901 - val_loss: 0.0651 - val_accuracy: 0.9793\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='adam' , metrics=['accuracy'])\n",
    "history1 = model1.fit(X_data_type, y_type,epochs=5, validation_split=0.2,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input2 = tf.keras.layers.Input(shape=(maxlen,))\n",
    " \n",
    "x2 = tf.keras.layers.Embedding(vocab_size2,100, weights=[embedding_matrix2], trainable=False)(input2)\n",
    "\n",
    "x2 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True, dropout=0.1,\n",
    "                                                      recurrent_dropout=0.1))(x2)\n",
    " \n",
    "x2 = tf.keras.layers.Conv1D(64, kernel_size=3, padding=\"valid\", kernel_initializer=\"glorot_uniform\")(x2)\n",
    " \n",
    "avg_pool2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "max_pool2 = tf.keras.layers.GlobalMaxPooling1D()(x2)\n",
    " \n",
    "x2 = tf.keras.layers.concatenate([avg_pool2, max_pool2])\n",
    " \n",
    "preds2 = tf.keras.layers.Dense(23, activation=\"sigmoid\")(x2)\n",
    " \n",
    "model2 = tf.keras.Model(input2, preds2)\n",
    " \n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 865 samples, validate on 217 samples\n",
      "Epoch 1/5\n",
      "865/865 [==============================] - 78s 91ms/sample - loss: 0.3589 - accuracy: 0.8679 - val_loss: 0.1993 - val_accuracy: 0.9565\n",
      "Epoch 2/5\n",
      "865/865 [==============================] - 61s 70ms/sample - loss: 0.1792 - accuracy: 0.9565 - val_loss: 0.1757 - val_accuracy: 0.9565\n",
      "Epoch 3/5\n",
      "865/865 [==============================] - 60s 69ms/sample - loss: 0.1612 - accuracy: 0.9565 - val_loss: 0.1609 - val_accuracy: 0.9565\n",
      "Epoch 4/5\n",
      "865/865 [==============================] - 61s 70ms/sample - loss: 0.1406 - accuracy: 0.9572 - val_loss: 0.1420 - val_accuracy: 0.9575\n",
      "Epoch 5/5\n",
      "865/865 [==============================] - 62s 72ms/sample - loss: 0.1182 - accuracy: 0.9605 - val_loss: 0.1265 - val_accuracy: 0.9613\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='adam' , metrics=['accuracy'])\n",
    "history2 = model2.fit(X_data_domain, y_domain,epochs=5, validation_split=0.2,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "labels_domain=['Artificial Intelligence' ,'Blockchain', 'C' ,'C++' ,'Cloud Computing',\n",
    " 'Coding', 'Data Science', 'Development Process', 'Finance' ,'Hardware',\n",
    " 'Higher Education' ,'IoT', 'Java' ,'Javascript', 'Machine Learning',\n",
    " 'Management' ,'Mobile Applications', 'Networking','Other','Python',\n",
    " 'Security' ,'Software Architecture', 'Web Development']\n",
    "\n",
    "labels_type=['Certifications','Competitions','Courses','Expos','Fests','Hackathon','Internships','Jobs','Talks','Training','Webinars','Workshops']\n",
    "def classify_event_type(x) :\n",
    "    event_set=pd.read_csv(x)\n",
    "    sentences = list(event_set[\"Event\"])\n",
    "    xvar=[]\n",
    "    type_list=[]\n",
    "    domain_list=[]\n",
    "    for sen in sentences:\n",
    "        xvar.append(preprocess_text(sen))\n",
    "    #sen=preprocess_text(sen)\n",
    "    #sen=np.array([sen])\n",
    "    tokenizer.fit_on_texts(xvar)\n",
    "\n",
    "    sen_data = tokenizer.texts_to_sequences(xvar)\n",
    "\n",
    "    maxlen = 200\n",
    "\n",
    "    sen_data = pad_sequences(sen_data, padding='post', maxlen=maxlen)\n",
    "    #print(sen_data.shape)\n",
    "    types=model1.predict(sen_data)\n",
    "    domains=model2.predict(sen_data)\n",
    "    \n",
    "    list1=np.argmax(types,axis=1)\n",
    "    list2=np.argmax(domains,axis=1)\n",
    "    for var in list1:\n",
    "        type_list.append(labels_type[var])\n",
    "    for var in list2:\n",
    "        domain_list.append(labels_domain[var])\n",
    "    #match(type_list,domain_list)\n",
    "    print(type_list)\n",
    "    print(domain_list)\n",
    "    emp_list=match(type_list,domain_list)\n",
    "    c=[]\n",
    "    for i in range(len(emp_list)):\n",
    "        c.append(\", \".join(emp_list[i]))\n",
    "                   \n",
    "        event_set['Name']=pd.Series(c)\n",
    "    #print(event_set)\n",
    "    event_set.to_excel(\"employee_list.xlsx\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(type_list,domain_list) :\n",
    "    emp_list=[]\n",
    "    emp=pd.read_csv(\"CCMLEmployeeData.csv\")\n",
    "    for x in range(3) :\n",
    "        z=[];\n",
    "        for index, row in emp.iterrows():\n",
    "            if(domain_list[x]!='Other'):\n",
    "                if((row['Event1']==type_list[x] or row['Event2']==type_list[x])and row['Domain']==domain_list[x]):\n",
    "                    z.append(row['Name'])\n",
    "            else :\n",
    "                if(row['Event1']==type_list[x] or row['Event2']==type_list[x]):\n",
    "                    z.append(row['Name'])\n",
    "\n",
    "\n",
    "        emp_list.append(z)\n",
    "\n",
    "    return(emp_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.33868040e-04 1.04583160e-04 6.33937214e-03 2.37145039e-04\n",
      "  9.02451866e-05 4.59352555e-03 3.05002229e-03 4.02053818e-04\n",
      "  2.52485261e-05 9.82651174e-01 8.46899784e-05 2.73429346e-03]\n",
      " [2.90888478e-03 5.28503326e-04 3.31001123e-04 9.52814706e-04\n",
      "  7.35225194e-06 1.55606722e-05 7.71391788e-04 4.36904338e-05\n",
      "  8.14802130e-04 4.29505249e-03 4.77907388e-03 9.89328444e-01]\n",
      " [8.22361946e-01 1.65787583e-07 2.14152824e-04 5.24841380e-06\n",
      "  6.99097939e-07 6.04337920e-03 5.31786878e-04 2.02908132e-06\n",
      "  1.12158254e-04 1.08808326e-03 1.17102936e-01 1.00177720e-04]]\n",
      "['Training', 'Workshops', 'Certifications']\n",
      "['Management', 'Networking', 'Javascript']\n",
      "                                               Event  \\\n",
      "0                       C++ hackathon is live now!!!   \n",
      "1                          Workshop on data science    \n",
      "2  EmbeddedTech India expo 2020 is from 21 march ...   \n",
      "\n",
      "                                                Name  \n",
      "0                         John Pearson, Michael Rowe  \n",
      "1                                     Janice Leonard  \n",
      "2  Kayla Young, Russell Vargas, Deborah Young, An...  \n"
     ]
    }
   ],
   "source": [
    "classify_event_type(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
